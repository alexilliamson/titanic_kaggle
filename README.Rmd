---
title: "Titanic"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(caret)
library(pROC)
library(magrittr)
```


### Data  

```{r}
labeled_df <- read_csv('data/train.csv', col_types = cols(
        PassengerId = col_integer(),
        Survived = col_integer(),
        Pclass = col_integer(),
        Name = col_character(),
        Sex = col_character(),
        Age = col_double(),
        SibSp = col_integer(),
        Parch = col_integer(),
        Ticket = col_character(),
        Fare = col_double(),
        Cabin = col_character(),
        Embarked = col_character())
        ) %>% 
        mutate(Survived = factor(Survived, levels = c(0,1), 
                                         labels = c('no_survive', 'survive') ))

submission_df <- read_csv('data/test.csv', col_types = cols(
        PassengerId = col_integer(),
        Pclass = col_integer(),
        Name = col_character(),
        Sex = col_character(),
        Age = col_double(),
        SibSp = col_integer(),
        Parch = col_integer(),
        Ticket = col_character(),
        Fare = col_double(),
        Cabin = col_character(),
        Embarked = col_character()
))
```

### Determine Predictors  

Which fields are present in both datasets?  

```{r}
combined_data <- submission_df %>% 
        mutate(IsTrain = FALSE) %>%
        bind_rows(mutate(labeled_df, IsTrain = TRUE))

combined_data %>%
        group_by(IsTrain) %>%
        summarise_all(~sum(is.na(.x)))
```

Select the non-missing features that would make sense as predictors

```{r}
predictors <- combined_data %>%
        select_if(~sum(is.na(.x)) == 0) %>%
        select(-PassengerId,-Name,-Ticket, -IsTrain) %>%
        names()

predictors
```

### Split training/holdout  

```{r}
set.seed(100)

train_index <- createDataPartition(labeled_df$Survived, p = 0.8, list = FALSE)

train_df <- labeled_df[train_index,]

holdout_df <- labeled_df[-train_index,]
```

### xgbTree model  

```{r}
set.seed(101)

ctrl <- trainControl(method = "repeatedcv",
                     classProbs = T,
                     summaryFunction = twoClassSummary,
                     number = 10, 
                     repeats = 5,
                     savePredictions = T)

xgbTree_train <- train(Survived ~ .,
                       data = train_df[,c('Survived',predictors)],
                       method = "xgbTree",
                       trControl = ctrl,
                       metric = 'ROC'
)
```

### Model summary  

```{r}
confusionMatrix(xgbTree_train)
```

### Holdout performance  

```{r}
holdout_preds <- predict(xgbTree_train, newdata = holdout_df, type = 'prob') %>%
        add_column(
                prediction = predict(xgbTree_train, 
                                     newdata = holdout_df, 
                                     type = 'raw'))

holdout_roc <- roc(holdout_df$Survived, holdout_preds$survive)

holdout_roc_df <- holdout_roc %$%
        tibble(tpr = sensitivities, fpr = 1 - specificities)
```

#### Confusion Matrix  

```{r}
confusionMatrix(holdout_df$Survived,holdout_preds$prediction)
```

#### ROC curve  

```{r}
holdout_roc_df %>%
        ggplot(aes(fpr,tpr)) +
        geom_line() +
        geom_abline(slope = 1, intercept = 0) +
        labs(title = 'Holdout ROC') +
        theme_bw()
```

#### AUC  

```{r}
holdout_auc <- ci.auc(holdout_roc) %>%
        as.numeric() %>%
        tibble(value = .) %>%
        mutate(description = c('lower','estimate','upper')) %>%
        spread(description, value)

holdout_auc %>%
        ggplot(aes('holdout auc', y = estimate) ) +
        geom_errorbar(aes(ymin = lower, ymax = upper)) +
        geom_label(aes(label = round(estimate, 3))) + 
        coord_flip() +
        theme_bw()
```
